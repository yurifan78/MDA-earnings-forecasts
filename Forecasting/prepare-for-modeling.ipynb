{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:56:10.916011Z",
     "end_time": "2023-08-14T16:56:12.692098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. truncate item 7 to avoid common parttern in text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(43290, 9)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('datasets/features-label.pkl')\n",
    "df_copy = df.copy()\n",
    "df_copy.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:56:20.735347Z",
     "end_time": "2023-08-14T16:57:03.072290Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "    CIK file_id  year       roe     opinc    nopinc  \\\n0  1750       3  2005  0.095362  0.131652 -0.015174   \n1  1750       4  2006  0.127945  0.149182 -0.022282   \n2  1750       7  2009  0.063607  0.105913 -0.030043   \n3  1750       8  2010  0.088296  0.136418 -0.040048   \n4  1750       9  2011  0.079613  0.138888 -0.026679   \n\n                                 preprocessed_item_7  token_count  \\\n0  [general, overview, report, activities, four, ...         2320   \n1  [forwardlooking, statements, managements, disc...         3419   \n2  [forwardlooking, statements, managements, disc...         3564   \n3  [forwardlooking, statements, managements, disc...         3245   \n4  [forwardlooking, statements, managements, disc...         2703   \n\n   roe_next_year  \n0       0.127945  \n1       0.139220  \n2       0.088296  \n3       0.079613  \n4       0.061607  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CIK</th>\n      <th>file_id</th>\n      <th>year</th>\n      <th>roe</th>\n      <th>opinc</th>\n      <th>nopinc</th>\n      <th>preprocessed_item_7</th>\n      <th>token_count</th>\n      <th>roe_next_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1750</td>\n      <td>3</td>\n      <td>2005</td>\n      <td>0.095362</td>\n      <td>0.131652</td>\n      <td>-0.015174</td>\n      <td>[general, overview, report, activities, four, ...</td>\n      <td>2320</td>\n      <td>0.127945</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1750</td>\n      <td>4</td>\n      <td>2006</td>\n      <td>0.127945</td>\n      <td>0.149182</td>\n      <td>-0.022282</td>\n      <td>[forwardlooking, statements, managements, disc...</td>\n      <td>3419</td>\n      <td>0.139220</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1750</td>\n      <td>7</td>\n      <td>2009</td>\n      <td>0.063607</td>\n      <td>0.105913</td>\n      <td>-0.030043</td>\n      <td>[forwardlooking, statements, managements, disc...</td>\n      <td>3564</td>\n      <td>0.088296</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1750</td>\n      <td>8</td>\n      <td>2010</td>\n      <td>0.088296</td>\n      <td>0.136418</td>\n      <td>-0.040048</td>\n      <td>[forwardlooking, statements, managements, disc...</td>\n      <td>3245</td>\n      <td>0.079613</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1750</td>\n      <td>9</td>\n      <td>2011</td>\n      <td>0.079613</td>\n      <td>0.138888</td>\n      <td>-0.026679</td>\n      <td>[forwardlooking, statements, managements, disc...</td>\n      <td>2703</td>\n      <td>0.061607</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:57:46.338871Z",
     "end_time": "2023-08-14T16:57:46.355384Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "CIK                     object\nfile_id                 object\nyear                     int64\nroe                    float64\nopinc                  float64\nnopinc                 float64\npreprocessed_item_7     object\ntoken_count              int64\nroe_next_year          float64\ndtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:58:22.410106Z",
     "end_time": "2023-08-14T16:58:22.420512Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# for text longer than 1000, remove the first and last 100 words\n",
    "# for text shorter than 1000, remove the first and last 50 words\n",
    "# update token count\n",
    "def remove_first_last_words(row):\n",
    "    words = row['preprocessed_item_7']\n",
    "    length = row['token_count']\n",
    "\n",
    "    if length < 1000:\n",
    "        words = words[50:-50]\n",
    "    else:\n",
    "        words = words[100:-100]\n",
    "\n",
    "    return words, len(words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T14:08:33.124666Z",
     "end_time": "2023-07-19T14:08:33.137433Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_copy[['preprocessed_item_7', 'token_count']] = df_copy.apply(remove_first_last_words, axis=1, result_type='expand')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T14:08:36.011256Z",
     "end_time": "2023-07-19T14:10:01.900902Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. split dataset and save train_ids and test_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# split by company\n",
    "# training and testing data 80% and 20%\n",
    "companies = df_copy[['CIK', 'file_id']].groupby('CIK')\n",
    "\n",
    "train_ids = []\n",
    "test_ids = []\n",
    "random_seed = 42\n",
    "\n",
    "for _, company in companies:\n",
    "    train_group, test_group = train_test_split(company, test_size=0.2, random_state = random_seed)\n",
    "    train_ids.append(train_group)\n",
    "    test_ids.append(test_group)\n",
    "\n",
    "train_ids = pd.concat(train_ids)[['file_id']]\n",
    "test_ids = pd.concat(test_ids)[['file_id']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T14:10:06.959064Z",
     "end_time": "2023-07-19T14:12:13.066002Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(32113, 1)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T14:12:24.276694Z",
     "end_time": "2023-07-19T14:12:24.317088Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(11177, 1)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T14:12:24.906529Z",
     "end_time": "2023-07-19T14:12:24.947770Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_ids.to_csv('train-test-ids/train-ids.csv', index=False)\n",
    "test_ids.to_csv('train-test-ids/test-ids.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T14:12:25.930829Z",
     "end_time": "2023-07-19T14:12:26.006061Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. represent item 7 by tone based on LMD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_m1_1 = df_copy.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate tone based on LMD\n",
    "lmd_neg = pd.read_csv('../LMD/LMD-neg-words.csv')\n",
    "lmd_pos = pd.read_csv('../LMD/LMD-pos-words.csv')\n",
    "\n",
    "def calculate_item7_tone(row):\n",
    "    text = row['preprocessed_item_7']\n",
    "    neg_count = 0\n",
    "    pos_count = 0\n",
    "\n",
    "    for word in text:\n",
    "        if word in lmd_neg:\n",
    "            neg_count += 1\n",
    "        if word in lmd_pos:\n",
    "            pos_count += 1\n",
    "\n",
    "    tone = (pos_count - neg_count) / len(text)\n",
    "\n",
    "    return tone"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_m1_1['tone'] = df_m1_1.apply(calculate_item7_tone, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. represent item 7 by word2vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use text from train data locally train word embedding model\n",
    "train_data = df_copy[df_copy['file_id'].isin(train_ids['file_id'])]\n",
    "train_data_text = train_data['preprocessed_item_7'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train word2vec model, using continuous bag-of-words algorithm\n",
    "word_embedding_100 = Word2Vec(train_data_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save word embedding model\n",
    "word_embedding_100.save('word-embedding/word-embedding-100.model')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train word2vec model, using skip-gram algorithm\n",
    "word_embedding_100_sg = Word2Vec(train_data_text, sg=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save word embedding model\n",
    "word_embedding_100_sg.save('word-embedding/word-embedding-100-sg.model')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use word embedding to represent text (the entire dataset)\n",
    "def get_text_vector(text, model):\n",
    "    vectors = [model.wv[word] for word in text if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_m1_2 = df_m1_1.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_m1_2['text_vector'] = df_m1_2['preprocessed_item_7'].apply(lambda x: get_text_vector(x, word_embedding_100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save features and label with text represented\n",
    "df_m1_2.to_pickle('datasets/features-label-text-represented.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
